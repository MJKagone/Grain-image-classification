{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from img2vec_pytorch import Img2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grain image classification\n",
    "\n",
    "This notebook loads a dataset of images of four kinds of different grains represented in .png format, trains machine learning models for classification, and tests the models.\n",
    "\n",
    "Choose the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"data/quantity\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for loading and processing the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img2vec = Img2Vec()\n",
    "\n",
    "def load_image(file, i):\n",
    "    if not file.lower().endswith(\".png\"):\n",
    "        raise Exception(\"Invalid file name\")\n",
    "    print(f\"Loading {file}\")\n",
    "    image = Image.open(file)\n",
    "    features = img2vec.get_vec(image)\n",
    "    label = i\n",
    "    return features, label\n",
    "\n",
    "def prepare_data(directory, data_file, labels_file):\n",
    "    failed_files = []\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    # load the images and labels from the directory\n",
    "    for i in range(4):\n",
    "        path = os.path.join(directory, [\"kaura\", \"ohra\", \"ruis\", \"vehna\"][i])\n",
    "        files = [os.path.join(path, file) for file in os.listdir(path)]\n",
    "        for j, file in enumerate(files):\n",
    "            # if (i == 0 and j % 10 != 0): # use this to reduce the size of the dataset\n",
    "            #     continue\n",
    "            try:\n",
    "                img, label = load_image(file, i)\n",
    "                data.append(img)\n",
    "                if label == 0:\n",
    "                    labels.append(0)\n",
    "                else:\n",
    "                    labels.append(1)\n",
    "                print(f\"Loaded {file}\")\n",
    "            except:\n",
    "                failed_files.append(file)\n",
    "                continue\n",
    "\n",
    "    if not failed_files:\n",
    "        print(\"All files loaded successfully\")\n",
    "    else:\n",
    "        print(f\"Failed to load files {failed_files}\")\n",
    "\n",
    "    # save the data and labels as numpy arrays for classification\n",
    "    data_np = np.array(data)\n",
    "    labels_np = np.array(labels)\n",
    "    print(\"Saving data...\")\n",
    "    np.save(data_file, data_np)\n",
    "    np.save(labels_file, labels_np)\n",
    "    print(f\"Data saved successfully in {data_file} and {labels_file}\")\n",
    "    return data_np, labels_np\n",
    "\n",
    "def load_cached(directory, data_file, labels_file):\n",
    "    try:\n",
    "        data, labels = np.load(data_file), np.load(labels_file)\n",
    "        print('Successfully loaded cached data')\n",
    "        return data, labels\n",
    "    except:\n",
    "        return prepare_data(directory, data_file, labels_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    if dataset == \"data/quality\":\n",
    "        x, y = load_cached(dataset + \"/train\", \"training_data_quality.npy\", \"training_labels_quality.npy\")\n",
    "    else:\n",
    "        x, y = load_cached(dataset + \"/train\", \"training_data_quantity.npy\", \"training_labels_quantity.npy\")\n",
    "    return x, y\n",
    "\n",
    "print(\"Loading data...\")\n",
    "x_train, y_train = load_data()\n",
    "print(\"Data loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the basic models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(x_train, y_train):\n",
    "\n",
    "    print(\"Training random forest model...\")\n",
    "    random_forest_model = RandomForestClassifier()\n",
    "    random_forest_model.fit(x_train, y_train)\n",
    "    if dataset == \"data/quality\":\n",
    "        pickle.dump(random_forest_model, open(\"random_forest_model_quality.sav\", 'wb'))\n",
    "        print(\"Random forest model trained successfully and saved in random_forest_model_quality.sav\")\n",
    "    else:\n",
    "        pickle.dump(random_forest_model, open(\"random_forest_model_quantity.sav\", 'wb'))\n",
    "        print(\"Random forest model trained successfully and saved in random_forest_model_quantity.sav\")\n",
    "\n",
    "    print(\"Training kNN model...\")\n",
    "\n",
    "    knn_model = KNeighborsClassifier()\n",
    "    knn_model.fit(x_train, y_train)\n",
    "    if dataset == \"data/quality\":\n",
    "        pickle.dump(knn_model, open(\"knn_model_quality.sav\", 'wb'))\n",
    "        print(\"kNN model trained successfully and saved in knn_model_quality.sav\")\n",
    "    else:\n",
    "        pickle.dump(knn_model, open(\"knn_model_quantity.sav\", 'wb'))\n",
    "        print(\"kNN model trained successfully and saved in knn_model_quantity.sav\")\n",
    "\n",
    "    print(\"Training MLP model...\")\n",
    "    MLP_model = MLPClassifier()\n",
    "    MLP_model.fit(x_train, y_train)\n",
    "    if dataset == \"data/quality\":\n",
    "        pickle.dump(MLP_model, open(\"MLP_model_quality.sav\", 'wb'))\n",
    "        print(\"MLP model trained successfully and saved in MLP_model_quality.sav\")\n",
    "    else:\n",
    "        pickle.dump(MLP_model, open(\"MLP_model_quantity.sav\", 'wb'))\n",
    "        print(\"MLP model trained successfully and saved in MLP_model_quantity.sav\")\n",
    "\n",
    "train_models(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the optimized models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(x_train, y_train):\n",
    "\n",
    "    print(\"Training random forest model...\")\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [200],\n",
    "        \"max_features\": [\"sqrt\", None],\n",
    "        \"max_samples\": [0.75, 1.0]\n",
    "    }\n",
    "    random_forest_model = GridSearchCV(RandomForestClassifier(), param_grid, n_jobs=-1, refit=True)\n",
    "    random_forest_model.fit(x_train, y_train)\n",
    "    if dataset == \"data/quality\":\n",
    "        pickle.dump(random_forest_model.best_estimator_, open(\"random_forest_model_o_quality.sav\", 'wb'))\n",
    "        print(\"Random forest model trained successfully and saved in random_forest_model_o_quality.sav\")\n",
    "    else:\n",
    "        pickle.dump(random_forest_model.best_estimator_, open(\"random_forest_model_o_quantity.sav\", 'wb'))\n",
    "        print(\"Random forest model trained successfully and saved in random_forest_o_model_quantity.sav\")\n",
    "    print(\"Best parameters: \", random_forest_model.best_params_)\n",
    "    print(\"Best score: \", round(random_forest_model.best_score_, 3))\n",
    "\n",
    "    print(\"Training kNN model...\")\n",
    "    param_grid = {\n",
    "        \"n_neighbors\": [3, 5, 7, 9, 11, 13],\n",
    "        \"metric\": [\"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\"],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "    }\n",
    "    knn_model = GridSearchCV(KNeighborsClassifier(), param_grid, n_jobs=-1, refit=True)\n",
    "    knn_model.fit(x_train, y_train)\n",
    "    if dataset == \"data/quality\":\n",
    "        pickle.dump(knn_model.best_estimator_, open(\"knn_model_o_quality.sav\", 'wb'))\n",
    "        print(\"kNN model trained successfully and saved in knn_model_o_quality.sav\")\n",
    "    else:\n",
    "        pickle.dump(knn_model.best_estimator_, open(\"knn_model_o_quantity.sav\", 'wb'))\n",
    "        print(\"kNN model trained successfully and saved in knn_model_o_quantity.sav\")\n",
    "    print(\"Best parameters: \", knn_model.best_params_)\n",
    "    print(\"Best score: \", round(knn_model.best_score_, 3))\n",
    "\n",
    "    print(\"Training MLP model...\")\n",
    "    param_grid = {\n",
    "        \"hidden_layer_sizes\": [(100,), (500,), (200, 200), (500, 50), (150, 100, 50), (500, 500, 500)],\n",
    "        \"activation\": [\"logistic\", \"relu\"],\n",
    "        \"learning_rate\": [\"constant\", \"invscaling\"],\n",
    "        \"alpha\": [0.0001, 0.001]\n",
    "    }\n",
    "    MLP_model = GridSearchCV(MLPClassifier(), param_grid, n_jobs=-1, refit=True)\n",
    "    MLP_model.fit(x_train, y_train)\n",
    "    if dataset == \"data/quality\":\n",
    "        pickle.dump(MLP_model.best_estimator_, open(\"MLP_model_o_quality.sav\", 'wb'))\n",
    "        print(\"MLP model trained successfully and saved in MLP_model_o_quality.sav\")\n",
    "    else:\n",
    "        pickle.dump(MLP_model.best_estimator_, open(\"MLP_model_o_quantity.sav\", 'wb'))\n",
    "        print(\"MLP model trained successfully and saved in MLP_model_o_quantity.sav\")\n",
    "    print(\"Best parameters: \", MLP_model.best_params_)\n",
    "    print(\"Best score: \", round(MLP_model.best_score_, 3))\n",
    "\n",
    "train_models(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"data/quality\":\n",
    "    x_test, y_test = load_cached(dataset + \"/holdout\", \"holdout_data_quality.npy\", \"holdout_labels_quality.npy\")\n",
    "else:\n",
    "    x_test, y_test = load_cached(dataset + \"/holdout\", \"holdout_data_quantity.npy\", \"holdout_labels_quantity.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the basic models on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_models(x_test, y_test):\n",
    "    fig, axs = plt.subplots(nrows=3, ncols=1, figsize=(8, 15))\n",
    "\n",
    "    models = [\"random_forest_model\", \"knn_model\", \"MLP_model\"]\n",
    "    titles = [\"RF\", \"KNN\", \"MLP\"]\n",
    "\n",
    "    set = \"L\" if dataset == \"data/quality\" else \"M\"\n",
    "\n",
    "    for i, model_name in enumerate(models):\n",
    "        if dataset == \"data/quality\":\n",
    "            model = pickle.load(open(f\"{model_name}_quality.sav\", 'rb'))\n",
    "        else:\n",
    "            model = pickle.load(open(f\"{model_name}_quantity.sav\", 'rb'))\n",
    "        accuracy = model.score(x_test, y_test)\n",
    "        print(f\"{titles[i]} accuracy: \", round(accuracy, 3))\n",
    "\n",
    "        y_pred = model.predict(x_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Kaura\", \"Ei-kaura\"])\n",
    "        disp.plot(ax=axs[i])\n",
    "        if model_name == \"random_forest_model\":\n",
    "            disp.im_.axes.set_title(f\"Satunnaismetsäluokitin\")\n",
    "        else:\n",
    "            axs[i].set_title(f\"{titles[i]}-luokitin\")\n",
    "        axs[i].set_xlabel(\"Ennustettu luokka\")\n",
    "        axs[i].set_ylabel(\"Todellinen luokka\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "evaluate_models(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the optimized models on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_models(x_test, y_test):\n",
    "    fig, axs = plt.subplots(nrows=3, ncols=1, figsize=(8, 15))\n",
    "\n",
    "    models = [\"random_forest_model\", \"knn_model\", \"MLP_model\"]\n",
    "    titles = [\"RF\", \"KNN\", \"MLP\"]\n",
    "\n",
    "    set = \"L\" if dataset == \"data/quality\" else \"M\"\n",
    "\n",
    "    for i, model_name in enumerate(models):\n",
    "        if dataset == \"data/quality\":\n",
    "            model = pickle.load(open(f\"{model_name}_o_quality.sav\", 'rb'))\n",
    "        else:\n",
    "            model = pickle.load(open(f\"{model_name}_o_quantity.sav\", 'rb'))\n",
    "        accuracy = model.score(x_test, y_test)\n",
    "        print(f\"{titles[i]} accuracy: \", round(accuracy, 3))\n",
    "\n",
    "        y_pred = model.predict(x_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Kaura\", \"Ei-kaura\"])\n",
    "        disp.plot(ax=axs[i])\n",
    "        if model_name == \"random_forest_model\":\n",
    "            disp.im_.axes.set_title(f\"Optimoitu satunnaismetsäluokitin\")\n",
    "        else:\n",
    "            axs[i].set_title(f\"Optimoitu {titles[i]}-luokitin\")\n",
    "        axs[i].set_xlabel(\"Ennustettu luokka\")\n",
    "        axs[i].set_ylabel(\"Todellinen luokka\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "evaluate_models(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test image files manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tkinter import filedialog\n",
    "# import tkinter as tk\n",
    "\n",
    "# model = pickle.load(open(\"MLP_model_quality.sav\", 'rb'))\n",
    "# while True:\n",
    "\n",
    "#     try:\n",
    "#         # open a file browser to select a file from your storage\n",
    "\n",
    "#         root = tk.Tk()\n",
    "#         root.withdraw()\n",
    "\n",
    "#         file_path = filedialog.askopenfilename()\n",
    "\n",
    "#         # read the image\n",
    "\n",
    "#         img = load_image(file_path, 0)[0]\n",
    "\n",
    "#         # predict the class\n",
    "\n",
    "#         prediction = model.predict([img])\n",
    "\n",
    "#         if prediction[0] == 0:\n",
    "#             print(\"Prediction: kaura\")\n",
    "#         elif prediction[0] == 1:\n",
    "#             print(\"Prediction: ohra\")\n",
    "#         elif prediction[0] == 2:\n",
    "#             print(\"Prediction: ruis\")\n",
    "#         elif prediction[0] == 3:\n",
    "#             print(\"Prediction: vehnä\")\n",
    "\n",
    "#     except:\n",
    "#         print(\"File browser closed\")\n",
    "#         break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
